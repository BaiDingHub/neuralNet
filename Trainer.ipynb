{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络模型训练器\n",
    "包括训练，等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelProcessor(object):\n",
    "    '''\n",
    "    包含处理model的各种函数\n",
    "    '''\n",
    "    def __init__(self,model,x,y):\n",
    "        '''\n",
    "        input:\n",
    "        model:神经网络模型\n",
    "        x:输入数据\n",
    "        y:输入标签\n",
    "        \n",
    "\n",
    "        self.reg:正则化参数\n",
    "        self.dropout:dropout参数,表示保留神经元的百分比\n",
    "        self.norm:批标准化参数,None为不标准化，\n",
    "        '''\n",
    "        self.reg = model.reg\n",
    "        self.dropout = model.dropout\n",
    "        self.use_norm = model.use_norm\n",
    "        self.model = model\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def train(self,epoch = 5,iterations = 1000,printFreq = 2):\n",
    "        '''\n",
    "        训练神经网络模型\n",
    "        输入:\n",
    "        epoch:训练整个数据集的次数,默认5\n",
    "        iterations:每次训练数据的个数,默认1000\n",
    "        printFreq:每五次迭代输出loss\n",
    "        '''\n",
    "        loss_history = []\n",
    "        acc_history = []\n",
    "        iter_epoch_num = (int(self.x.shape[0] / iterations) + 1)    #一个迭代次数\n",
    "        iter_nums = iter_epoch_num * epoch\n",
    "        configs = {}\n",
    "        for i in range(iter_nums):\n",
    "            random_index = np.random.choice(self.x.shape[0],iterations)\n",
    "            batch_x = self.x[random_index]\n",
    "            batch_y = self.y[random_index]\n",
    "            loss ,grads= self.model.loss(batch_x,batch_y)\n",
    "            score,acc = self.model.predict(batch_x,batch_y)\n",
    "            loss_history.append(loss)\n",
    "            acc_history.append(acc)\n",
    "            for value in grads.keys():                  #更新参数\n",
    "                if i == 0:\n",
    "                    configs[value] = model.config.copy()\n",
    "                self.model.params[value] = model.grad_function(self.model.params[value],grads[value],configs[value])    \n",
    "            if (i+1) % printFreq == 0:                  #输出loss\n",
    "                print('第',int(i/iter_epoch_num)+1,'/',epoch,'epoch','第',i %iter_epoch_num + 1,'次迭代:',\n",
    "                      'loss:',loss,'||    accuracy:',acc)\n",
    "\n",
    "        return loss_history,acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
